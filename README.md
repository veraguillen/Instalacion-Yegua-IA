# EL BANQUETE DE LAS YEGUAS: InstalaciÃ³n ArtÃ­stica Interactiva con IA

> **Una exploraciÃ³n sobre el acoso callejero a travÃ©s de la VisiÃ³n por Computadora y el Deep Learning**

<div align="center">
  <img src="https://placehold.co/1200x400/1a1a2e/e94560?text=EL+BANQUETE+DE+LAS+YEGUAS" alt="Banner del Proyecto" width="100%">
  <p><em>Interfaz de la instalaciÃ³n interactiva - DetecciÃ³n en tiempo real</em></p>
</div>

## Resumen Ejecutivo

**YEGUA** es una instalaciÃ³n de arte digital reactiva que utiliza **Inteligencia Artificial** en tiempo real para generar conciencia sobre el acoso. El sistema monitorea el entorno mediante una cÃ¡mara y clasifica la presencia de espectadores para detonar una respuesta audiovisual inmersiva:

### Estados de la InstalaciÃ³n
- **Estado Acoso (Yegua detectada)**
  - Ambiente sonoro intenso y luces intermitentes
  - VisualizaciÃ³n de texto con frases de acoso reales
  - Efectos visuales de distorsiÃ³n

- **Estado Seguro (Persona sin mÃ¡scara)**
  - MÃºsica ambiental relajante
  - IluminaciÃ³n suave y estable
  - Mensajes de empoderamiento

- **Estado VacÃ­o (Sin movimiento)**
  - Pantalla en reposo
  - Bucle de espera de bajo consumo
  - Mensaje de bienvenida intermitente

Este proyecto demuestra un **ciclo completo de Ciencia de Datos (End-to-End)**, desde la ingenierÃ­a de datos hasta el despliegue en producciÃ³n sin conexiÃ³n (Edge AI) en dispositivos de bajo rendimiento.

---

## Tech Stack & Herramientas

### Stack TecnolÃ³gico

| Ãrea | TecnologÃ­as |
|------|-------------|
| **Lenguaje** | Python 3.10+ |
| **Deep Learning** | TensorFlow 2.15, Keras (MobileNetV2) |
| **Computer Vision** | OpenCV 4.8+ |
| **Data Engineering** | DuckDuckGo Search, Requests, Pillow (PIL) |
| **Interfaz/Audio** | Pygame 2.5+ |
| **OptimizaciÃ³n** | TensorFlow Lite (para versiÃ³n mÃ³vil) |
| **Deployment** | PyInstaller (Standalone .exe) |
| **Control de Versiones** | Git, GitHub |
| **DocumentaciÃ³n** | Markdown, MkDocs

---

## Data Pipeline (IngenierÃ­a de Datos)

### AdquisiciÃ³n de Datos
Dado que no existÃ­a un dataset pÃºblico para esta mÃ¡scara especÃ­fica, se desarrollÃ³ un pipeline ETL completo:

#### 1. ExtracciÃ³n de Datos (Web Scraping)
- **Script:** `scripts/descargar_dataset.py`
- **Fuentes:** BÃºsqueda automatizada con `duckduckgo_search`
- **Filtros:** 
  - TamaÃ±o mÃ­nimo: 640x480px
  - Formatos: JPG, PNG, WebP
  - Licencia: Dominio pÃºblico/CC0
- **Manejo de Errores:**
  - Timeouts configurados
  - Reintentos automÃ¡ticos
  - Control de User-Agent

#### 2. Limpieza y EstandarizaciÃ³n
- **Script:** `scripts/estandarizar_imagenes.py`
- **Procesamiento:**
  - ConversiÃ³n a RGB (3 canales)
  - RedimensiÃ³n a 224x224px
  - NormalizaciÃ³n de histograma
  - EliminaciÃ³n de duplicados (hash perceptual)
- **OrganizaciÃ³n:**
  - Estructura de carpetas por clase
  - Metadatos en JSON

#### 3. Aumento de Datos
- **TÃ©cnicas Aplicadas:**
  - RotaciÃ³n: Â±30Â°
  - Zoom: 20%
  - Desplazamiento: 10% (horizontal/vertical)
  - Volteo horizontal
  - VariaciÃ³n de brillo/contraste
- **Ratio:** 5x aumento del dataset original

---

## Modelado y Arquitectura

Se utilizÃ³ **Transfer Learning** sobre la arquitectura **MobileNetV2** (pre-entrenada en ImageNet). Esta red fue seleccionada por su arquitectura ligera (Depthwise Separable Convolutions), ideal para inferencia en tiempo real en CPUs estÃ¡ndar.

## Arquitectura del Modelo

```python
# ExtracciÃ³n de caracterÃ­sticas con MobileNetV2
base_model = MobileNetV2(
    weights="imagenet",
    include_top=False,
    input_shape=(224, 224, 3)
)
base_model.trainable = False  # Congelar pesos pre-entrenados

# Capas personalizadas
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation="relu"),
    Dropout(0.5),  # RegularizaciÃ³n para evitar overfitting
    Dense(1, activation="sigmoid")  # ClasificaciÃ³n Binaria
])

# ConfiguraciÃ³n de entrenamiento
model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss="binary_crossentropy",
    metrics=["accuracy", tf.keras.metrics.AUC()]
)
```

### Estrategias de Entrenamiento
- **Transfer Learning:** Aprovechamiento de pesos pre-entrenados en ImageNet
- **RegularizaciÃ³n:** Dropout del 50% para prevenir sobreajuste
- **Callbacks:**
  - EarlyStopping: Paciencia de 5 Ã©pocas
  - ModelCheckpoint: Guardado del mejor modelo
  - ReduceLROnPlateau: ReducciÃ³n dinÃ¡mica del learning rate

## EvaluaciÃ³n y MÃ©tricas

El modelo fue evaluado rigurosamente en un conjunto de validaciÃ³n independiente (20% de los datos):

### MÃ©tricas Principales
| MÃ©trica               | Valor    | InterpretaciÃ³n                          |
|-----------------------|----------|-----------------------------------------|
| **Accuracy**          | 97.55%   | PrecisiÃ³n global del modelo             |
| **Precision**         | 0.98     | Bajo nÃºmero de falsos positivos         |
| **Recall**            | 0.97     | Buen balance entre clases               |
| **F1-Score**          | 0.975    | Media armÃ³nica de precisiÃ³n y recall    |
| **Latencia (CPU)**    | ~97 ms   | Rendimiento en tiempo real aceptable     |
| **Tasa de FPS**       | ~10 FPS  | Fluidez adecuada para la instalaciÃ³n     |

### Matriz de ConfusiÃ³n
![Matriz de ConfusiÃ³n](analysis/confusion_matrix.png)

*La matriz muestra un equilibrio Ã³ptimo entre las dos clases, con un mÃ­nimo de falsos positivos/negativos que podrÃ­an afectar la experiencia del usuario.*

## LÃ³gica de Inferencia en Tiempo Real

El sistema implementa un pipeline de procesamiento optimizado en `main.py`:

### Flujo de Procesamiento
1. **DetecciÃ³n de Movimiento**
   - AnÃ¡lisis de diferencia de cuadros (frame differencing)
   - Umbral adaptativo para diferentes condiciones de iluminaciÃ³n
   - Filtrado de ruido con operaciones morfolÃ³gicas

2. **Pre-procesamiento**
   - Redimensionamiento a 224x224 pÃ­xeles
   - NormalizaciÃ³n de pÃ­xeles (0-1)
   - Aumento de contraste (CLAHE)

3. **ClasificaciÃ³n**
   - Inferencia con el modelo MobileNetV2 optimizado
   - Suavizado temporal con media mÃ³vil (3 frames)
   - Umbral de confianza ajustable

### MÃ¡quina de Estados

```mermaid
stateDiagram-v2
    [*] --> VACIO
    VACIO --> DETECCION: Movimiento detectado
    
    state DETECCION {
        [*] --> PREPROCESAR
        PREPROCESAR --> INFERENCIA
        INFERENCIA --> DECIDIR
        
        state DECIDIR {
            [*] --> UMBRAL
            UMBRAL --> |Confianza > 0.7| CLASIFICAR
            UMBRAL --> |Confianza <= 0.7| VACIO
            
            state CLASIFICAR {
                [*] --> ES_YEGUA
                ES_YEGUA --> |SÃ­| ACOSO
                ES_YEGUA --> |No| SEGURO
            }
        }
    }
    
    ACOSO --> VACIO: Timeout (30s)
    SEGURO --> VACIO: Sin movimiento (5s)
```

### Optimizaciones
- **Inferencia por Lotes:** Procesamiento por lotes cuando es posible
- **GestiÃ³n de Memoria:** LiberaciÃ³n explÃ­cita de recursos
- **Threading:** Procesamiento en segundo plano para mantener la fluidez
- **Logging:** Registro detallado para depuraciÃ³n

## GuÃ­a de InstalaciÃ³n

### Requisitos del Sistema
- **Sistema Operativo:** Windows 10/11, macOS 10.15+, o Linux
- **Python:** 3.10 o superior
- **CÃ¡mara Web:** ResoluciÃ³n mÃ­nima 720p recomendada
- **Espacio en Disco:** 1GB libre (incluyendo el modelo y dependencias)
- **RAM:** MÃ­nimo 4GB (8GB recomendado)

### InstalaciÃ³n desde CÃ³digo Fuente

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/veraguillen/Instalacion-Yegua-IA.git
   cd el-banquete-de-las-yeguas
   ```

2. **Configurar entorno virtual (recomendado)**
   ```bash
   python -m venv venv
   .\venv\Scripts\activate  # Windows
   source venv/bin/activate  # Linux/Mac
   ```

3. **Instalar dependencias**
   ```bash
   pip install -r requirements.txt
   ```

4. **Ejecutar la aplicaciÃ³n**
   ```bash
   python main.py
   ```
   *El sistema abrirÃ¡ una ventana de configuraciÃ³n inicial para seleccionar la cÃ¡mara y ajustar parÃ¡metros.*

### VersiÃ³n Ejecutable (Standalone)

Para instalaciones en entornos de exhibiciÃ³n sin Python:

1. **Descargar el paquete**
   - Disponible en [Releases](https://github.com/veraguillenm/el-banquete-de-las-yeguas/releases)
   - Versiones para Windows (.exe), macOS (.app) y Linux (.AppImage)

2. **InstalaciÃ³n**
   - **Windows:** Ejecutar `Yegua_Instalacion_Setup.exe`
   - **macOS:** Arrastrar a la carpeta Aplicaciones
   - **Linux:** Dar permisos de ejecuciÃ³n y ejecutar

3. **Primera EjecuciÃ³n**
   - La aplicaciÃ³n incluye todos los recursos necesarios
   - Se recomienda una calibraciÃ³n inicial de cÃ¡mara

### ConfiguraciÃ³n Avanzada

El archivo `config.json` permite personalizar:
- Umbrales de detecciÃ³n
- Rutas de recursos
- ParÃ¡metros de rendimiento
- ConfiguraciÃ³n de audio/visual

## Estructura del Proyecto

```
el-banquete-de-las-yeguas/
â”‚
â”œâ”€â”€ assets/                    # Recursos multimedia
â”‚   â”œâ”€â”€ audio/                 # Pistas de audio
â”‚   â”‚   â”œâ”€â”€ ambiente/          # Sonidos de fondo
â”‚   â”‚   â””â”€â”€ efectos/           # Efectos de sonido
â”‚   â””â”€â”€ fonts/                 # Fuentes tipogrÃ¡ficas
â”‚
â”œâ”€â”€ data/                      # Datos y modelos
â”‚   â”œâ”€â”€ processed/             # Datos procesados
â”‚   â”‚   â”œâ”€â”€ train/             # Conjunto de entrenamiento
â”‚   â”‚   â”‚   â”œâ”€â”€ yegua/        # ImÃ¡genes positivas
â”‚   â”‚   â”‚   â””â”€â”€ nada/         # ImÃ¡genes negativas
â”‚   â”‚   â””â”€â”€ val/              # Conjunto de validaciÃ³n
â”‚   â”œâ”€â”€ raw/                  # Datos sin procesar
â”‚   â””â”€â”€ models/               # Modelos guardados
â”‚       â””â”€â”€ modelo_yegua.keras
â”‚
â”œâ”€â”€ analysis/                 # AnÃ¡lisis y mÃ©tricas
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ training_history.png
â”‚   â””â”€â”€ classification_report.txt
â”‚
â”œâ”€â”€ scripts/                  # Herramientas
â”‚   â”œâ”€â”€ data/                
â”‚   â”‚   â”œâ”€â”€ descargar_dataset.py
â”‚   â”‚   â””â”€â”€ estandarizar_imagenes.py
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ train_model.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ main.py                  # Punto de entrada principal
â”œâ”€â”€ requirements.txt         # Dependencias
â”œâ”€â”€ setup.py                # Script de instalaciÃ³n
â””â”€â”€ README.md               # Este archivo
```

### DescripciÃ³n de Carpetas

- **/assets**: Contiene todos los recursos multimedia necesarios para la instalaciÃ³n.
- **/data**: OrganizaciÃ³n clara de datos crudos, procesados y modelos.
- **/analysis**: Reportes y visualizaciones para evaluaciÃ³n del modelo.
- **/scripts**: Herramientas modulares para el procesamiento de datos y entrenamiento.

## Sobre la Artista y Desarrolladora

### Vera GuillÃ©n
**Artista Digital & Desarrolladora de Software**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/vera-guillen-9b464a303/)
[![Portfolio](https://img.shields.io/badge/Portfolio-View_Projects-FF4088?style=for-the-badge&logo=vercel)](https://vera-guillen.vercel.app/)
[![GitHub](https://img.shields.io/badge/GitHub-Repository-181717?style=for-the-badge&logo=github)](https://github.com/veraguillenm)

### DeclaraciÃ³n ArtÃ­stica
*"Este proyecto busca generar reflexiÃ³n sobre el acoso callejero a travÃ©s de la interacciÃ³n con tecnologÃ­as emergentes. Al convertir al espectador en partÃ­cipe activo, la instalaciÃ³n invita a experimentar fÃ­sicamente las dinÃ¡micas de poder que se generan en el espacio pÃºblico, cuestionando los lÃ­mites entre lo pÃºblico y lo privado, lo Ã­ntimo y lo colectivo."*

---

## Licencia

Este proyecto estÃ¡ bajo la Licencia [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/).

[![CC BY-NC-SA 4.0][cc-by-nc-sa-shield]][cc-by-nc-sa]

[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/
[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg

---

## Contribuciones

Las contribuciones son bienvenidas. Por favor, lee las [guÃ­as de contribuciÃ³n](CONTRIBUTING.md) antes de enviar un pull request.

## Contacto

Para consultas sobre exposiciones, colaboraciones o preguntas tÃ©cnicas:
- âœ‰ï¸ contacto@veraguillen.art
- ğŸŒ [veraguillen.art](https://veraguillen.art)

---

<div align="center">
  <sub>Creado con â¤ï¸ por Vera GuillÃ©n | 2023</sub>
</div>